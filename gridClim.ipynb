{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff2cf07-bc99-46ad-807f-af0629c1a4e3",
   "metadata": {},
   "source": [
    "# A look at gridclim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bcb45f-6ee2-4ea2-b1e1-98fb19b96b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small helper lib.\n",
    "import attribution\n",
    "\n",
    "# Others.\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.quickplot as qplt\n",
    "import iris.plot as iplt\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as scstats\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70888b08-d86a-4563-9c48-072a1070a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=2)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdf9bb-7a10-4d88-b86c-4dcfa9168d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sweref projection.\n",
    "sweref = ccrs.epsg(3006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7fb11-0f66-4f69-9ebd-e805875e5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains shapes of most countries in the world.\n",
    "# https://www.naturalearthdata.com/downloads/10m-cultural-vectors/10m-admin-0-boundary-lines/\n",
    "fname = \"/home/sm_erhol/data/ne_10_admin_0_countries/ne_10m_admin_0_countries.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96c871-9d63-4d73-bbd9-9fe21164abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ce2c5-8935-44d7-be5f-ebd551bf2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Sweden.\n",
    "swe_shapes = gdf[gdf.SOVEREIGNT == \"Sweden\"].geometry\n",
    "swe_mainland = swe_shapes.iloc[0].geoms[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08eb95c-c36b-4317-b63a-546feef31dc5",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Let's load the SweGridClim data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b3290-66c1-429f-8cdd-11557627feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/nobackup/smhid17/proj/sik/SMHIGridClim_NORDIC-11/v0.9/netcdf/day/pr/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a478118-f3be-4dcf-8a86-fd49c45acefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives a list of files in the base path matchig the wildcard.\n",
    "files = glob.glob(base_path + \"*.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9c60e-ed79-4fe2-a7c5-7740dd794d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = iris.load(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9c6ba-93a0-407a-b1f1-5145e3e74ca1",
   "metadata": {},
   "source": [
    "We want to merge these cubes to one, or concatenate?\n",
    "But have to remove some attributes first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd035f1-7456-4380-aa78-20e96c897f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = iris.util.equalise_attributes(cube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78054793-4611-46ac-8552-881602bbbc4e",
   "metadata": {},
   "source": [
    "Now we should hopefully be able to concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19f03b-e3ce-4a2f-bdeb-38924637dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We concat on time.\n",
    "cube = cube.concatenate_cube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ae219-eea5-42e9-88f4-80c52ea975df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec34aec8-c567-42ca-9109-d3e43815926a",
   "metadata": {},
   "source": [
    "Extract data for Sweden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69febe60-002f-4705-b0bf-5c7af0a0f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b55d8d0-8fa3-4cfd-a413-25e3ee5ec279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask from a polygon, using func from iris_utils.\n",
    "# This should work on 2 and 3d cubes.\n",
    "mask = iris_utils.utils.mask_from_shape(\n",
    "    cube, swe_mainland, coord_names=(\"grid_latitude\", \"grid_longitude\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bbfd8-b390-47fa-93ce-bb52300e0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will modify the cube in place as well.\n",
    "iris_utils.mask_cube(cube, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7265047a-4268-417d-8879-035c1be371e7",
   "metadata": {},
   "source": [
    "## Event definition\n",
    "- It rained 161 mm in 24 hours in G채vle during the event.\n",
    "- This corresponds to an intensity of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51f300-34ed-4630-b89e-de4f064f5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [mm s or kg/m2/s]\n",
    "threshold = 161 / (24 * 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33114e6-771c-40a2-a3e6-d536ba31554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158be725-2dda-4704-8bc9-cd7617878913",
   "metadata": {},
   "source": [
    "which can define as the event to look for.\n",
    "\n",
    "We can do this quickly in the whole of GridClim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540cedac-a7c5-46df-9c80-09215cb4977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.core_data().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9156cde-d62c-437a-8816-89da312067c2",
   "metadata": {},
   "source": [
    "This however raises the question, is it a fair comparison to take the daily intensity of the gridded product and compare it to station data like this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac7383-db1b-45fd-8239-1d468dba3ed9",
   "metadata": {},
   "source": [
    "## Region selection\n",
    "We probably don't want to look over all of Sweden.\n",
    "Which region should we select the data over?\n",
    "Some box around G채vle, where data should be homogeneous.\n",
    "\n",
    "Could make an average map and use this to select an area around POI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2eee3-e49d-4277-a12a-1ea60926e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_cube = cube.collapsed(\"time\", iris.analysis.MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8f4bc-6604-43ce-adfc-a3f5ac75af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_points = [[14.5, 14.5, 19.5, 19.5], [57.7, 61.2, 57.7, 61.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0af37b-bd1c-43db-9c33-f5b89eaaf1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G채vle point\n",
    "lat = 60.73284099330242\n",
    "lon = 17.09885344649177\n",
    "fig, ax = plt.subplots(figsize=(7, 9), subplot_kw={\"projection\": sweref})\n",
    "iplt.contourf(clim_cube, 30, axes=ax)\n",
    "ax.scatter([lon], [lat], s=50, transform=ccrs.PlateCarree(), label=\"G채vle\")\n",
    "ax.scatter(\n",
    "    mask_points[0],\n",
    "    mask_points[1],\n",
    "    s=50,\n",
    "    c=\"k\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    label=\"Box corners\",\n",
    ")\n",
    "\n",
    "ax.coastlines()\n",
    "ax.legend()\n",
    "ax.set_title(\"Average precipitation flux\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43abbc4-1cf6-4acf-8f37-19fbd8866989",
   "metadata": {},
   "source": [
    "We then have to convert the coordinates to the CoordSystem of our cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ca1ba-ef09-4a5c-93e2-23d5a3f3a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coord system of the cube. Convert it to cartopy.\n",
    "target_projection = cube.coord_system().as_cartopy_projection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8973b-d130-46ff-b2d6-e910e86293c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mask points to ndarray\n",
    "points = np.asarray(mask_points)\n",
    "# Transform them to the cube projection.\n",
    "transformed_points = target_projection.transform_points(\n",
    "    ccrs.PlateCarree(), points[0, :], points[1, :]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526167bf-f097-42f9-af44-89486cc16b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transformed coordinates of the bounding box.\n",
    "np.save(\"./data/region_points_transformed\", transformed_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca601570-d546-4f42-935a-509d550be322",
   "metadata": {},
   "source": [
    "Create a constraint from the converted corner coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a896b80-6e9e-4e03-8ac1-c9243594dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the constraint.\n",
    "region_constraint = iris.Constraint(\n",
    "    grid_latitude=lambda v: transformed_points[:, 1].min()\n",
    "    < v\n",
    "    < transformed_points[:, 1].max(),\n",
    "    grid_longitude=lambda v: transformed_points[:, 0].min()\n",
    "    < v\n",
    "    < transformed_points[:, 0].max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1990529-7ecb-4f95-8f9b-85f0b75925a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And extract the region.\n",
    "reg_cube = cube.extract(region_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2835f-8786-4e7f-8f14-4f438d191f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7285e-11de-4eb8-b6bb-0d9c02c2ea3f",
   "metadata": {},
   "source": [
    "Look at the selected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e81a4-8c41-40f9-bca0-aab641fd3cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G채vle point\n",
    "lat = 60.73284099330242\n",
    "lon = 17.09885344649177\n",
    "fig, ax = plt.subplots(figsize=(7, 9), subplot_kw={\"projection\": sweref})\n",
    "iplt.contourf(reg_cube[0, :, :], 30, axes=ax)\n",
    "ax.scatter([lon], [lat], s=50, transform=ccrs.PlateCarree(), label=\"G채vle\")\n",
    "ax.scatter(\n",
    "    mask_points[0],\n",
    "    mask_points[1],\n",
    "    s=20,\n",
    "    c=\"k\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    label=\"Box corners\",\n",
    ")\n",
    "\n",
    "ax.coastlines()\n",
    "ax.legend()\n",
    "# Set the extent to put the data into context.\n",
    "ax.set_extent([10, 20, 50, 75], crs=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3338d911-9a50-42a0-b3ab-d7c51b29fb52",
   "metadata": {},
   "source": [
    "## Fitting an extreme value distribution to Rx1\n",
    "Now we can start looking at the extremes, e.g. annual Rx1.\n",
    "In this case Rx1 should simply be the annual max?\n",
    "Since we already have daily values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f9b7e-a263-4bf6-8ca4-93b99315ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a year categorisation\n",
    "iris.coord_categorisation.add_year(reg_cube, \"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25071b-6951-4aa3-b649-330c832d5cec",
   "metadata": {},
   "source": [
    "Get the annual maximums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d699d-9fc1-4cf6-8a9f-852b0b16dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rx1_ann = reg_cube.aggregated_by(\"year\", iris.analysis.MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb7ce2-f1df-49e3-9c6d-f00f789f0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, density is way above one since the bin values are so small.\n",
    "# e.g. the widht of each bin is ~0.0001, hence integrating = 1\n",
    "plt.hist(rx1_ann.data.compressed(), density=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5fe056-cedd-46f6-bc2c-68b25755f355",
   "metadata": {},
   "source": [
    "### Fit a GEV distribution.\n",
    "We use scipy to fit a GEV distribution to this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79574483-57fd-4419-94f6-acab9fdf4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GEV dist object\n",
    "dist = scstats.genextreme\n",
    "# data\n",
    "data = rx1_ann.data.compressed()\n",
    "# And fit the data\n",
    "fit = dist.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be540f55-aa57-496b-9fbc-a74958a4fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe48725-9183-431e-bf11-b12f17a991dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get an nx3 array of the fit params.\n",
    "# results = attribution.bootstrap_fit(data, dist)\n",
    "# np.save(\"./data/fits_ci_gridclim\", results)\n",
    "# If we've already ran tha bootstrap.\n",
    "results = np.load(\"./data/fits_ci_gridclim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f06ed-2b78-4275-bb13-a413e511fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_ci = np.quantile(results, [0.05, 0.5, 0.95], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b7104-0131-4fc0-9a25-4cdb87dc2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c14a5-0f69-4349-9f06-65cf617a026f",
   "metadata": {},
   "source": [
    "## Regression to GMST\n",
    "To scale the above distribution with the use of GMST we first need to fit a regression between the Rx1 and GMST.\n",
    "The slope of the regression can then be used for the scaling.\n",
    "\n",
    "But first we load the GISTEMP data from NASA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a625214-9976-464d-b10f-e208bfe28e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives us the smoothed gmst data  for the timespan\n",
    "# covered by the cube.\n",
    "gmst_data = attribution.get_gmst(reg_cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5653b-7d71-4e42-ad16-57a080d500c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get the data of the rx1 cube.\n",
    "# Reshape to flatten the spatial dimensions.\n",
    "rx1_ann_data = rx1_ann.data.reshape(58, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8d5ad-cf6f-4be6-a65b-42fed659106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that first dimensions match.\n",
    "assert rx1_ann_data.shape[0] == gmst_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc09d2-0a7f-4433-9444-704955e90697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to look at the data.\n",
    "# fig, ax = plt.subplots(figsize=(7, 7))\n",
    "# ax.scatter(np.broadcast_to(gmst_data, rx1_ann_data.shape).flatten(),\n",
    "#                             rx1_ann_data.flatten(), s=5);\n",
    "# ax.set_xlabel(\"GMST\")\n",
    "# ax.set_ylabel(\"Precipitation intensity\");\n",
    "# ax.set_title(\"Pooled region scatter\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a641f73-da89-4073-bbe9-09d51bb8eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the linear regression we use Sklearn.\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86099adc-f3b1-47c6-acd7-5e77e28bba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can make clever use of the multiregression feature, we want\n",
    "# know the regression for each point.\n",
    "reg = LinearRegression().fit(gmst_data, rx1_ann_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf668f4-80d4-4410-9e2d-d028191a11f9",
   "metadata": {},
   "source": [
    "We scale the distribution by making the location and scale a function of the temperature anomaly, using the slope of the regression.\n",
    "\n",
    "$\\mu = \\mu_0 \\mathrm{exp}(\\alpha T' / \\mu_0),\\, \\sigma = \\sigma_0\\mathrm{exp}(\\alpha T'/ \\mu_0)$\n",
    "\n",
    "This is implemented in the `attribution.scale_dist_params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f0b82-bbb9-4698-8ed3-7a642a3b4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create current climate dists with CI\n",
    "dists_ci = [dist(*fit) for fit in fits_ci]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9715d-66be-4a2c-908e-2ce1f01610e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scaled_dists = attribution.scale_distributions(fits_ci, reg, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18634e76-0494-4b0c-8bbf-66ce119ce2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution.plot_distribution(data, dists_ci, all_scaled_dists, title=\"Rx1 GridClim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef5cce3-3336-40ad-b012-ffd42fc4ef38",
   "metadata": {},
   "source": [
    "## Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ca5a2e-0fd6-4b21-b7f0-624e60ffbb64",
   "metadata": {},
   "source": [
    "The probability ratio(s) (PR) for an event the magnitude of the G채vle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc72f15-1317-4ddd-a93a-5f17407f1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ratios = attribution.get_probability_ratios(dists_ci, all_scaled_dists, 0.0018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f80fe3-c803-4b73-a6f7-f39a85ece813",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/pr_gridclim\", prob_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf1ec3-4adf-4dc8-be20-c47eb15647c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128e858-a449-4c25-bffd-aeebd7cf34ff",
   "metadata": {},
   "source": [
    "Since the PR CI include 1 we cannot make a attribution statement for this event."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
