{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f1d89a7-cbdd-4873-8b25-4188a2bb942b",
   "metadata": {},
   "source": [
    "# Eobs data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a922ba-2e38-4b96-bc09-03644999b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small helper lib.\n",
    "import attribution.funcs\n",
    "import attribution.bootstrap\n",
    "\n",
    "# Others.\n",
    "from functools import partial\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.quickplot as qplt\n",
    "import iris.plot as iplt\n",
    "from iris.time import PartialDateTime\n",
    "import iris_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as scstats\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from climix.metadata import load_metadata\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d52d0d-c6bc-4405-8e0d-fddc905a3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust this address from gridClim notebook.\n",
    "client = Client(\"127.0.0.1:38409\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f8ea0-6125-4825-91ed-651d2c34a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344728c8-89e9-4309-90b2-29a7f272c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/nobackup/rossby26/users/sm_erhol/extremeEventAttribution/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87f421-529a-4542-bfd0-a21ee0b1cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sweref projection.\n",
    "sweref = ccrs.epsg(3006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a111ba-f61f-4f84-838f-f0a378858b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains shapes of most countries in the world.\n",
    "# https://www.naturalearthdata.com/downloads/10m-cultural-vectors/10m-admin-0-boundary-lines/\n",
    "fname = \"/home/sm_erhol/data/ne_10_admin_0_countries/ne_10m_admin_0_countries.shp\"\n",
    "\n",
    "gdf = gpd.read_file(fname)\n",
    "\n",
    "# Select Sweden.\n",
    "swe_shapes = gdf[gdf.SOVEREIGNT == \"Sweden\"].geometry\n",
    "swe_mainland = swe_shapes.iloc[0].geoms[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79465a45-6efb-46e4-bdb4-2bb7919e5474",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8579955b-1c30-44de-a930-c94ac14643e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we have to read the gridclim cube\n",
    "# We only need this for the first extraction, to limit how much data we are dealing with.\n",
    "base_path = \"/nobackup/smhid17/proj/sik/SMHIGridClim_NORDIC-11/v0.9/netcdf/day/pr/\"\n",
    "\n",
    "# This gives a list of files in the base path matchig the wildcard.\n",
    "files = glob.glob(base_path + \"*.nc\")\n",
    "\n",
    "cube = iris.load(files)\n",
    "\n",
    "removed = iris.util.equalise_attributes(cube)\n",
    "\n",
    "# We concat on time.\n",
    "cube = cube.concatenate_cube()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12aeff8-ecad-4d7c-aa82-49d2fd22a988",
   "metadata": {},
   "source": [
    "Start working on the EOBS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76df645-4609-40d8-a640-31adeb1dc268",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_eobs = \"/home/rossby/imports/obs/EOBS/EOBS24-0e/EUR-10/remap/EUR-11/day/\"\n",
    "files = glob.glob(base_path_eobs + \"pr*.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe61e3-f8dc-4760-b2c7-3dd6e84ff5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eobs_cube = iris.load(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17140313-6c6b-4afb-93cf-3c22a418e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to equalise the attributes in order to concatenate.\n",
    "removed = iris.util.equalise_attributes(eobs_cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0f11d-b246-48c4-b7c5-11f507a0f33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eobs_cube = eobs_cube.concatenate_cube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331a020-d7f5-4384-9cd1-1286cd389e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We extract the data over the GridClim region. No need for all of Europe.\n",
    "ref_lats = grid_latitude = cube.coord(\"grid_latitude\").points\n",
    "ref_lons = grid_longitude = cube.coord(\"grid_longitude\").points\n",
    "# First year\n",
    "pdt1 = PartialDateTime(year=1971)\n",
    "# Last day of GridClim does not include the 31st.\n",
    "pdt2 = PartialDateTime(year=2018, month=12, day=30)\n",
    "# Define the constraint.\n",
    "constraint = iris.Constraint(\n",
    "    grid_latitude=lambda v: ref_lats.min() <= v <= ref_lats.max(),\n",
    "    grid_longitude=lambda v: ref_lons.min() <= v <= ref_lons.max(),\n",
    "    time=lambda cell: pdt1 <= cell.point <= pdt2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d811e-941c-47f4-899d-5b37d1241f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract.\n",
    "eobs_cube = eobs_cube.extract(constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50ecba-a8e4-4cd9-a59e-baf1c467eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "eobs_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac4104-690a-4a98-86e9-718684084be9",
   "metadata": {},
   "source": [
    "## Region selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b30f5-3eb2-468a-840b-04bcc03d9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load in the transformed points generated in the eobs notebook.\n",
    "# We can do this since the cubes share coordinate system.\n",
    "mask_points = np.load(os.path.join(data_path, \"etc/region_points_transformed.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063dad02-4d5f-4a61-be8b-7e570fcf722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the constraint.\n",
    "region_constraint = iris.Constraint(\n",
    "    grid_latitude=lambda v: mask_points[:, 1].min() <= v <= mask_points[:, 1].max(),\n",
    "    grid_longitude=lambda v: mask_points[:, 0].min() <= v <= mask_points[:, 0].max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a6788-68e2-4742-b8c1-1275703cb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the region\n",
    "reg_cube = eobs_cube.extract(region_constraint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0727674b-f007-4a98-bd79-08a9cca1fe6a",
   "metadata": {},
   "source": [
    "Make sure the region selection worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219af52a-4486-4836-abbf-27a2ecf7b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 9), subplot_kw={\"projection\": sweref})\n",
    "iplt.contourf(reg_cube[15000, :, :], 30, axes=ax)\n",
    "ax.coastlines()\n",
    "# ax.legend();\n",
    "# Set the extent to put the data into context.\n",
    "ax.set_extent([10, 20, 50, 75], crs=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc606e7-4298-4fb3-9791-9ccd43599089",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Rx1 annual\n",
    "Now we can start looking at the extremes, e.g. annual Rx1.\n",
    "In this case Rx1 should simply be the annual max?\n",
    "Since we already have daily values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f81129-6a00-43d3-9cb0-595a21c6c5bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Event definition\n",
    "\n",
    "161 mm in 24 hours gives the threshold for the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3fb66-2e37-4c18-aa29-e67d0fd6f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 161"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896cf12-b2a6-42c4-a5fd-da909d613357",
   "metadata": {},
   "source": [
    "Use Climix to compute Rx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842537c-d235-4ae7-a52a-674fbd04e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index catalog\n",
    "catalog = load_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad1a5d-f4b6-4aa8-a21f-a9ae7ee6f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "rx1_ann_index = catalog.prepare_indices([\"rx1day\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1500abf9-aa41-4a05-b0de-8fe7f21c3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't have a year coordiante when passing to climix.\n",
    "try:\n",
    "    reg_cube.remove_coord(\"year\")\n",
    "except iris.exceptions.CoordinateNotFoundError:\n",
    "    pass\n",
    "rx1_ann = rx1_ann_index([reg_cube], client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba7f11d-d408-40e2-8397-182b18853d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask.\n",
    "mask = iris_utils.mask_from_shape(\n",
    "    rx1_ann, swe_mainland, coord_names=(\"grid_latitude\", \"grid_longitude\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5962e-734c-4e51-ae5a-527b309842ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This mask inplace as well.\n",
    "iris_utils.mask_cube(rx1_ann, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3965dd-f2f8-4045-b786-77ef7df18539",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rx1_ann.data.compressed(), density=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ff5b6-2015-40bc-9e3c-00688b764e12",
   "metadata": {},
   "source": [
    "### Fitting an extreme value distribution to Rx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79574483-57fd-4419-94f6-acab9fdf4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some extreme value distributions.\n",
    "dists = {\n",
    "    \"genextreme\": scstats.genextreme,\n",
    "    \"genpareto\": scstats.genpareto,\n",
    "    \"gamma\": scstats.gamma,\n",
    "    \"gengamma\": scstats.gengamma,\n",
    "    \"gumbel_l\": scstats.gumbel_l,\n",
    "    \"gumbel_r\": scstats.gumbel_r,\n",
    "}\n",
    "# data\n",
    "data = rx1_ann.data.compressed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03e35b-7985-4d69-9488-bac13a30e083",
   "metadata": {},
   "source": [
    "Before we do the bootstrap, we want to check the goodness of fit for the distribution and the data.\n",
    "For this we use a Kolmogorov-Smirnof test (KS-test).\n",
    "For a goodness of fit this is a bit unintuitive.\n",
    "The 0-hypothesis is that the distributions are the same, hence we are looking for a high p-value here. e.g. that we can't say that the dists are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f4c2f-18aa-42ee-86f6-2ccdc139ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit each distribution and evaluate KS test.\n",
    "for key, dist in dists.items():\n",
    "    fit = dist.fit(data)\n",
    "    print(f\"{key}:\", scstats.ks_1samp(data, dist.cdf, args=fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe65d4fd-0eaa-42fb-acc7-1576c10153de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, density is way above one since the bin values are so small.\n",
    "x = np.linspace(0, 120, 200)\n",
    "# e.g. the widht of each bin is ~0.0001, hence integrating to 1\n",
    "plt.hist(rx1_ann.data.compressed(), bins=20, density=True)\n",
    "for key, dist in dists.items():\n",
    "    fit = dists[key].fit(data)\n",
    "    plt.plot(x, dists[key].pdf(x, *fit), label=key)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5cff76-8425-4a9e-862a-a349ed974bb9",
   "metadata": {},
   "source": [
    "For a KS-test high p-value = we can't reject the null hypothesis that they are from the same distributions.\n",
    "\n",
    "$\\rightarrow$ the GEV distribution has the better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061bebc7-adde-4bed-987f-0049f902bb02",
   "metadata": {},
   "source": [
    "### Regression to GMST\n",
    "To scale the above distribution with the use of GMST we first need to fit a regression between the Rx1 and GMST.\n",
    "The slope of the regression can then be used for the scaling.\n",
    "\n",
    "But first we load the GISTEMP data from NASA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121e720-f2e2-4a29-8b8c-b2f0307be477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to gmst\n",
    "gmst_path = os.path.join(data_path, \"etc/gistemp.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a625214-9976-464d-b10f-e208bfe28e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives us the smoothed gmst data  for the timespan\n",
    "# covered by the cube.\n",
    "gmst_data = attribution.funcs.get_gmst(rx1_ann, path=gmst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec5bd6-ce66-4e42-878c-c148525cf81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get the data of the rx1 cube.\n",
    "rx1_ann_data = np.zeros((rx1_ann.shape[0], rx1_ann.data[0, :, :].compressed().shape[0]))\n",
    "# We need to compress the data for each year. This has to be done\n",
    "# in a loop I think.\n",
    "for i, year in enumerate(rx1_ann.data):\n",
    "    rx1_ann_data[i] = year.compressed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d1365-4794-432a-85c4-96b4ccc09969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that first dimensions match.\n",
    "assert rx1_ann_data.shape[0] == gmst_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a641f73-da89-4073-bbe9-09d51bb8eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the linear regression we use Sklearn.\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86099adc-f3b1-47c6-acd7-5e77e28bba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can make clever use of the multiregression feature, we want\n",
    "# know the regression for each point.\n",
    "reg = LinearRegression().fit(gmst_data, rx1_ann_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f24f34-e653-4494-8b5f-87f6266e4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We broadcast the slopes to have a slope for each entry in the pooled data.\n",
    "slopes_broad = np.broadcast_to(reg.coef_.reshape(1, -1), rx1_ann_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791fcaf1-e5de-422e-a8ef-cfe931aeaf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_broad = slopes_broad.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b1190-6a28-48e2-8aa8-07a5fa04cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should now have the same shape.\n",
    "assert slopes_broad.shape == data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3404d1-b780-4184-a979-d595c590809a",
   "metadata": {},
   "source": [
    "### Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ce34f-8552-4f17-a1c2-345c567271b0",
   "metadata": {},
   "source": [
    "The probability ratio(s) (PR) for an event the magnitude of the Gävle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1e3eb-e82b-42c1-ba50-ff041e43c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a partial function of calc_prob_ratio which can be passed\n",
    "# to the bootstrap.\n",
    "# temperature indicates to which temperature we scale the counterfactua\n",
    "# climate. In this case we want a climate that is 1.2 degrees colder.\n",
    "calc_prob_ratio_p = partial(\n",
    "    attribution.funcs.calc_prob_ratio,\n",
    "    threshold=threshold,\n",
    "    temperature=-1.2,\n",
    "    dist=dists[\"genextreme\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39788734-ff77-43eb-b996-fec3d270edbc",
   "metadata": {},
   "source": [
    "Calculate the probability ratio for EOBS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb85dc0-fed4-458a-aed9-7d084413d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the bootstrapped CI of the probability ratio\n",
    "rx1_ann_pbr_ci, rx1_ann_pbr_med, theta_hat_b = attribution.bootstrap.bootstrap_mp(\n",
    "    (data, slopes_broad), calc_prob_ratio_p, n_resamples=9999, batch=1, client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd332e-c7fa-41f2-b8cf-47052bedf248",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ratios_ci = np.asarray(\n",
    "    [\n",
    "        rx1_ann_pbr_ci.confidence_interval.low,\n",
    "        rx1_ann_pbr_med,\n",
    "        rx1_ann_pbr_ci.confidence_interval.high,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b54c7d1-5518-4b80-ae50-25bad984585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ratios_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f80fe3-c803-4b73-a6f7-f39a85ece813",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(data_path, \"etc/rx1-ann_prb_eobs\"), prob_ratios_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012d3320-a23b-4aa5-896e-02487e461533",
   "metadata": {},
   "source": [
    "## Next step\n",
    "\n",
    "[Preparing Cordex data](./prepare_cordex.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
